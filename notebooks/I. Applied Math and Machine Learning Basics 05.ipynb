{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Created by Petteri Nevavuori.*\n",
    "\n",
    "---\n",
    "\n",
    "# Deep Learning seminaari\n",
    "\n",
    "Kirjana Goodfellow et al.: Deep Learning (2016)\n",
    "\n",
    "Otsikot seuraavat pääotsikoiden tasolla kirjaa, mutta alaotsikot eivät aina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#5.-Machine-Learning-Basics\" data-toc-modified-id=\"5.-Machine-Learning-Basics-1\">5. Machine Learning Basics</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1.-Learning-Algorithms\" data-toc-modified-id=\"5.1.-Learning-Algorithms-1.1\">5.1. Learning Algorithms</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tehtävä,-$T$\" data-toc-modified-id=\"Tehtävä,-$T$-1.1.1\">Tehtävä, $T$</a></span></li><li><span><a href=\"#Suorituskyky,-$P$\" data-toc-modified-id=\"Suorituskyky,-$P$-1.1.2\">Suorituskyky, $P$</a></span></li><li><span><a href=\"#Kokemus,-$E$\" data-toc-modified-id=\"Kokemus,-$E$-1.1.3\">Kokemus, $E$</a></span></li></ul></li><li><span><a href=\"#5.1.1-Linear-Regression\" data-toc-modified-id=\"5.1.1-Linear-Regression-1.2\">5.1.1 Linear Regression</a></span></li><li><span><a href=\"#5.2.-Capacity,-Underfitting-and-Overfitting\" data-toc-modified-id=\"5.2.-Capacity,-Underfitting-and-Overfitting-1.3\">5.2. Capacity, Underfitting and Overfitting</a></span></li><li><span><a href=\"#5.3.-Hyperaparameters-and-Validation-Sets\" data-toc-modified-id=\"5.3.-Hyperaparameters-and-Validation-Sets-1.4\">5.3. Hyperaparameters and Validation Sets</a></span></li><li><span><a href=\"#5.4.-Estimators,-Bias-and-Variance\" data-toc-modified-id=\"5.4.-Estimators,-Bias-and-Variance-1.5\">5.4. Estimators, Bias and Variance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimointi\" data-toc-modified-id=\"Estimointi-1.5.1\">Estimointi</a></span></li><li><span><a href=\"#Vääristymä\" data-toc-modified-id=\"Vääristymä-1.5.2\">Vääristymä</a></span></li><li><span><a href=\"#Varianssi\" data-toc-modified-id=\"Varianssi-1.5.3\">Varianssi</a></span></li><li><span><a href=\"#Bias-Variance-Tradeoff\" data-toc-modified-id=\"Bias-Variance-Tradeoff-1.5.4\">Bias-Variance Tradeoff</a></span></li></ul></li><li><span><a href=\"#5.5.-Maximum-Likelihood-Estimation\" data-toc-modified-id=\"5.5.-Maximum-Likelihood-Estimation-1.6\">5.5. Maximum Likelihood Estimation</a></span></li><li><span><a href=\"#5.6.-Bayesian-Statistics\" data-toc-modified-id=\"5.6.-Bayesian-Statistics-1.7\">5.6. Bayesian Statistics</a></span></li><li><span><a href=\"#5.7.-Supervised-Learning\" data-toc-modified-id=\"5.7.-Supervised-Learning-1.8\">5.7. Supervised Learning</a></span></li><li><span><a href=\"#5.8.-Unuspervised-Learning\" data-toc-modified-id=\"5.8.-Unuspervised-Learning-1.9\">5.8. Unuspervised Learning</a></span></li><li><span><a href=\"#5.9.-Stochastic-Gradient-Descent\" data-toc-modified-id=\"5.9.-Stochastic-Gradient-Descent-1.10\">5.9. Stochastic Gradient Descent</a></span></li><li><span><a href=\"#5.10.-Perinteiset-menetelmät-vs.-syväoppivat-menetelmät\" data-toc-modified-id=\"5.10.-Perinteiset-menetelmät-vs.-syväoppivat-menetelmät-1.11\">5.10. Perinteiset menetelmät vs. syväoppivat menetelmät</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Machine Learning Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Syväoppivat menetelmät rakentavat vahvasti perinteisempien koneoppimismenetelmien perustalle. Useimmilla malleilla on niihin spesifisti liittyviä parametreja, *hyperparametreja*, joilla voidaan säädellä mallin toimintaa (mm. oppimiskerroin). Koneoppimisessa sovelletaan tilastotiedettä, painopisteenään tietokoneiden käyttö monimutkaisten dataa kuvaavien funktioiden approksimoinnissa. Koneoppimismenetelmät voidaan pääpiirteittäin jakaa kahteen leiriin, ohjatusti oppiviin (*supervised learning*) ja ohjaamattomasti oppiviin (*unsupervised learning*). Useimmat menetelmät hyödyntävät optimointialgoritminaan stokasista jyrkimmän laskun menetelmää (*stochastic gradient descent*), jossa sana stokastinen viittaa dataa tuottavan prosessin satunnaisuuteen ja riippumattomuuteen sen todennäköisyysjakauman osalta (*i.i.d., independent and identically distributed*). Data määrittyy usein piirteiden (*feature*) perusteella, joita menetelmät oppivat painottamaan tai hyödyntämään kulloisenkin tehtävän mukaisesti. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.1. Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Kirjassa koneoppimisalgoritmi määritellään seuraavasti:\n",
    "\n",
    "> *\"Koneoppimisalgoritmi on datasta oppimaan kykenevä algoritmi.\"*\n",
    "\n",
    "Oppiminen määritellään seuraavasti:\n",
    "\n",
    "> \"*Algoritmin voidaan sanoa oppivan kokemuksesta $E$ (*experience*) tehtävän $T$ (*task*) mukaisesti suorituskyvyllä $P$ (*performance*), mikäli sen suorituskyky kasvaa kyseisessä tehtävässä kokemuksien myötä.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Koneoppimismallit pyrkivät parhaiten kuvailemaan niille syötetyt datasetit. Loogisesti tämä on mahdollista vain, mikäli mallilla on pääsy kaikkiin datasetin näytteisiin. Käytännnössä tämä on mahdotonta. Siksi koneoppimismallit pyrkivät ennemmin tarjoamaan datasetin kuvaamiseen liittyviä todennäköisyyksiä, jolloin jotkin opitut säännöt ovat todennäköisesti tosia suurimmalle osaa datasetin näytteistä. Koneoppimismallit ovat myös pääsääntöisesti käyttökelpoisia vain omissa kapeahkoissa käyttöalueissaan. Vaikka keskiarvolla mikään malli ei ole toistaan parempi, mikäli malleja tarkastellaan \\*kaikkien mahdollisten\\* todennäköisyysjakaumien ja tehtävien kohdalla, ei näin objektiivista tilannetta voida koskaan saavuttaa. Todellisuudessa eri ilmiöille voidaan löytää toisistaan eroavia todennäköisyysjakaumia, jolloin jotkut mallit voivat osoittautua toistaan paremmiksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Tehtävä, $T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Koneoppimismenetelmiä voidaan käyttää ratkaisemaan erinäisiä tehtäviä hyvinkin kirjavasta joukosta. Näitä ovat ainakin:\n",
    "\n",
    " - **Luokittelu** (*classification*): Luokittelussa algoritmi pyrkii sijoittamaan sille annetun syötteen johonkin luokkaan. Näin vaikkapa hahmontunnistuksessa, jossa kuvista pyritään luokittelemaan niistä löytyvät esineet/asiat. Luokittelua voidaan tehdä myös puuttellisilla syötedatoilla, mutta tällöin yhden koko datasettiä kuvaavan funktion sijasta menetelmä pyrkii oppimaan joukon funktioita, jotka yhdessä kuvaavat datasettiä sen repaleisuudesta huolimatta.\n",
    " \n",
    " - **Ennustaminen** (*regression*): Tässä tehtävässä algoritmi pyrkii tuottamaan lukumuotoisen ennusteen perustuen sille annettuun syötedataan. Tehtävä on samankaltainen luokittelun kanssa, joskin opitun funktion arvojoukko on lukuja luokkien sijasta.\n",
    " \n",
    " - **Kuvailu** (*transcription*): Algoritmin tavoitteena on esimerkiksi tulkita kuva ja sen sisältö sanallisessa muodossa. Tätä voi olla esimerkiksi tekstin tunnistaminen kuvista, jossa koneelle luontaisesti lukukelvoton tietomuoto muutetaan koneluettavaksi - näin vaikkapa Google Street Viewin ja osoitenumeroiden tunnistuksen kohdalla.\n",
    " \n",
    " - **Konetulkkaus** (*machine translation*): Tässä tehtävässä algoritmille on opetettu joukko funktioita, jotka kykenevät tuottamaan tekstien käännöksiä kieleltä toiselle huomioiden kohde- ja lähdekielien kielioppisäännöt ja sanaston.\n",
    " \n",
    " - **Jäsentely** (*structured output*): Tehtävänä tämä on jo selkeästi laajempi. Esimerkiksi luonnollisen kielen prosessoinnissa (*natural language processing, NLP*) jäsentelyä voisi olla lauseiden jäsentäminen puurakenteeseen kieliopin perusteella. Toisaalta pikselitasolla tapahtuva kuvien luokittelu vaikkapa satelliittikuvista on myös jäsentämättömän tiedon jäsentämistä.\n",
    " \n",
    " - **Poikkeamien havaitseminen** (*anomaly detection*): Tässä algoritmin tehtävänä on oppia tavanomaiset ja sallitut tapahtumat ja samoin oppia erottelemaan näistä poikkeavat riittävällä varmuudella. Käytännössä tämä voi olla huijausten tunnistamista esimerkiksi luottoasioissa tai laitteiden toiminnassa.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Suorituskyky, $P$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Jotta algoritmi kykenee korjaamaan itseään, on sillä oltava käytettävissään koneoppimistehtävään sopiva suorituskykymittari. Luokittelun tapauksessa tämä mitta voi olla luokittelutarkkuus (*accuracy*) tai kääntäen virhetaso (*error rate*). Reaalilukujen tapauksissa on käytettävä niihin paremmin sopivia mittareita. Koska lähestulkoon kiinnostavinta koneoppimismalleissa on niiden yleistettävyys ennalta kohtaamattomiin syötteisiin (*generalization*), data jaetaan usein koulutussettiin (*training set*) ja testisettiin (*test set*). Sanomattakin lienee selvää, että menetelmien kirjon ohella myös suorituskykymittareita löytyy useita. Tärkeintä on määrittää tarkoin mitä tahdotaan mitata suhteutettuna valittuun tehtävään ja malliin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Kokemus, $E$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Kokemuksella tarkoitetaan laajassa mielessä kaikkea sitä, mitä algoritmin annetaan kokea koulutuksen yhteydessä. Toisin sanoen kokemuksen käsite liittyy olennaisesti datasettiin, jolla ja jolle algoritmi koulutetaan. Datasetti ja oppimistehtävä yhdessä määrittävät vahvasti, mitä ja millä tavalla algoritmeille syötetään dataa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Ohjaamattomassa oppimisessa** (*unsupervised learning*) algoritmille syötetään datasetti näyte kerrallaan. Algoritmin tehtäväksi jää sitten löytää yksittäisistä näytteistä koko datasettiä kuvaavia yleisiä piirteitä tai ominaisuuksia, jotka voidaan sitten mahdollisuuksien mukaan yleistää laajempaan, vielä havaitsemattomaan näytejoukkoon. Koska näytteistä puuttuu niin sanotut kohteet, ei algoritmia kouluteta ennustamaan tai luokittelemaan. Se voi kuitenkin ryhmitellä riittävän samankaltaisia näytteitä omiin joukkoihinsa(*clustering*) tai pyrkiä oppimaan datasetin taustalla vaikuttavat todennäköisyysfuntion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Ohjatussa oppimisessa** (*supervised learning*) algoritmille annetaan näytteiden lisäksi totuus kustakin näytteestä, eli luokka (*label*) tai tavoiteluku (*target*). Näin algoritmi opetetaan joko luokittelemaan tai ennustamaan pelkän dataan pohjautuvan ryhmittelyn sijasta; syötteeseen liitetty totuusarvo toimii opettajana. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Täysin selkeää rajaa ei näiden kahden välille voida kuitenkaan vetää. Ohjaamattoman oppimisen ongelma voidaan pilkkoa yksittäisiksi ohjatun oppimisen ongelmiksi, kun taas ohjatun oppimisen ongelma voidaan ratkaista ensin oppimalla ongelmaan liittyvän datasetin todennäköisyysfunktio ohjaamattomasti ja sen jälkeen johtamalla siitä ohjatun oppimisen vaatimat kohdearvot. Muita rajatun datasetin oppimiskategorioita ovat mm. osittain ohjattu oppiminen (*semi-supervised learning*), jossa kohdearvot on tiedossa vain osalla näytteistä. Moni-instanssisessa oppimisessa (*multi-instance learning*) kokonaisia joukkoja on kerralla luokiteltu, joskaa yksittäisillä näytteillä tätä tietoa ei ole talletettuna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Datasetti voi olla rajatun lisäksi myös jatkuvasti muuttuva. Tällöin esimerkiksi ollaan **vahvistuoppimisen** (*reinforcement learning*) alueella. Tällöin algoritmit ovat vuorovaikutuksessa ympäristönsä kanssa saaden sieltä palautetta korjaten itseään palautteen perusteella ja toimien sen jälkeen parhaimman päivitetyn tietonsa perusteella. Toisin sanoen kokemukset ja oppiminen ovat takaisinkytketyt toisiinsa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Datasetit on tavallista kuvata matriisimuodossa, jossa sarakkeet vastaavat datasetin piirteitä ja rivit yksittäisiä näytteitä eli havaintoja. Tällöin datasetti voidaan esittää esimerkiksi matriisina $X \\in \\mathbb{R}^{155 \\times 4}$, jolloin datasetissä on neljä piirrettä ja 155 havaintoa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Konkretisoiva esimerkki koneoppimisesta on lineaarinen regressio (*linear regression*), jollaa voidaan ratkaista regression eli ennustamisen ongelmia; algoritmimme $T$ on regressio. Yksinkertaisimmillaan tavoitteena on rakentaa järjestelmä, joka saadessaan syötteenä vektorin $x \\in \\mathbb{R}^n$ antaa tulokseksi skalaariarvon $y \\in \\mathbb{R}$. Kosksa kyseessä on lineaarinen regressio, menetelmän tulokset ovat syötteiden lineaarikombinaatioita. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mallin tuottama ennuste $\\hat{y}$ määritellään seuraavasti:\n",
    "\n",
    "$$ \\hat{y} = w^Tx,$$\n",
    "\n",
    "jossa $w \\in \\mathbb{R}^n$ on parametri- tai painovektori. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tällä painovektorilla painotetaan jokainen vektorin $x$ alkio. Siksi se on tämän yksinkertaisen algoritmin koulutuksen kohteena. Jotta mallia voidaan kouluttaa tarvitaan vielä ainakin mittari mallin suorituskyvyn arvioimiseksi. Mittariksi kelpaa virheiden neliöiden keskiarvo (*mean squared error, MSE*); $P$ on virheiden neliöiden keskiarvo. Datasetti jaetaan kahtia koulutus- ja testisetteihin. Siinä tulee myös olemaan tiedot kohdearvoista; $E$ on ohjatun oppimisen alueella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Kun määriteltyä suorituskykymittarifunktiota $P$ minimoidaan päivittämällä mallin painovektoria $w$ iteratiivisesti, päästään iteraatio kerrallaan kohti testisettiin nähden mahdollisimman tarkkoja ennusteita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2. Capacity, Underfitting and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Koneoppimisen ydinhaasteena on jo aiemminkin mainittu yleistettävien (*generalizing*) mallien tuottaminen. Kuten jo aiemminkin esitelty, tätä tavoitellaan jakamalla datasetit koulutus- ja testisetteihin. Mallia ei ikinä kouluteta testisetillä, mutta sen suorituskykyä mitataan perinteisesti vain sillä. Tilastollisen oppimisteoriaan (*statistical learning theory*) pohjaten lähtökohtana on, että sekä koulutus- että testisettien näytteet ovat pohjimmiltaan saman datantuottoprosessin (*data-generating process*) tuotoksia ja täyttävät rippumattomuuden ja yhtenevän taustajakauman (*i.i.d*) oletukset. Tällöin näiden kahden näytejoukon taustalla oleva datatuottojakauma on yhtenevä. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lähtökohtaisesti siis satunnaisesti valitun koulutussetin näytteen virheen ei pitäisi poiketa testisetin näytteen virheestä keskimäärin. Tällöin koneoppimisalgoritmien tavoitteet saadaan yksinkertaistettua seuraavasti:\n",
    "\n",
    " 1. Pienennä koulutusvirhettä.\n",
    " 2. Kavenna koulutus- ja testivirheiden eroa.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mikäli algoritmi ei kykene pienentämään koulutusvirhettä riittävästi, se alisovittuu (*underfit*) suhteessa koulutussettiin. Jos taas algoritmi oppii koulutussetin liian hyvin, eli koulutus- ja testivirheiden välillä on merkittävä ero, algoritmi ylisovittuu (*overfit*) suhteessa koulutussettiin. Malliin liittyen tätä tasapainoa voidaan säädellä vaikuttamalla mallin kapasiteettiin (*capacity*), siihen, kuinka laajan kirjon erilaisia funktioita malli saa hyödyntää oppiessaan. Tätä kutsutaan tarkemmin edustavaksi kapasiteetiksi (*representational capacity*). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lineaarisen regression ongelmassa kapasiteetin lisääminen tarkoittaisi esimerkiksi polynomien sallimista lineaarikombinaatioiden lisäksi, jolloin kullekin näytteen alkiolle etsittäisin alkion kertoimen lisäksi kerroin sen neliölle. Esimerkkikaavana se näyttäisi tältä:\n",
    "\n",
    "$$ \\hat{y} = b + w_1x + w_2x^2 .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mikäli mallin kapasiteetti on liian suuri, se ylisovittuu helposti. Liian pienellä kapasiteetilla se taas alisovittuu. Tämä on vielä visualisoitu alla yksinkertaisella koodilla, jossa satunnaisesti generoituun dataan sovitetaan eriasteisia suoria. Oikeinpuolimmaisin (`deg=7`) selkeästi ylisovittuu kohinaan, kun taas vasemmanpuoleisin (`deg=1`) ei löydä datasta mitään varsinaisesti yleistä kulmakerrointa kummempaa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABA4AAAEICAYAAADfv7b6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBBCCHFK/x+75taTwtpBzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fd5034edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = 18, 4\n",
    "\n",
    "data_x = np.arange(1, 11)\n",
    "data_y = np.random.rand(10) * 5\n",
    "x = np.arange(1, 101) / 10\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    deg = (2 * i + 1)\n",
    "    w = np.polyfit(data_x, data_y, deg=deg)\n",
    "    p = np.poly1d(w)\n",
    "    pred_y = p(x)\n",
    "\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.title(\"deg={}\".format(deg))\n",
    "    plt.scatter(data_x, data_y)\n",
    "    plt.plot(x, pred_y,)\n",
    "    plt.xlim(0, 10)\n",
    "    plt.ylim(0, 5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Edustavan kapasiteetin suhteen optimaalisen ratkaisun löytäminen on kuitenkin useimmiten työlästä. Muuttamalla mallin parametreja ei löydetä välttämättä parasta mallia, vaan vain malli, joka pienentää koulutuksen aikaista virhettä merkittävästi. Kun huomioidaan mallin optimoinnin haasteet, voidaan alkaa puhua käytännöllisestä kapasiteetista (*effective capacity*), joka on pienempi tai enintään yhtä suuri edustavan kapasiteetin kanssa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Käytännössä tällä erottelulla tahdotaan ilmaista lausetta\n",
    "\n",
    "> *\"Monimutkaisempi ei tarkoita aina parempaa\"*\n",
    "\n",
    "tai toisin kääntäen\n",
    "\n",
    "> *\"Yksinkertaisempi on parempi\"* (Occamin partaveitsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Yksiselitteisestä tämä ei kuitenkaan ole. Vaikka tilastollisen oppimisteorian puolella on kehitetty keinoja optimaalisen mallin kapasiteetin määrittämiseen esimerkiksi luokittelun ongelmissa, syväoppivat menetelmät eivät näistä keinoista juuri hyödy. Mallin ja sen parametrien sijasta käytännöllisen kapasiteetin pullonkaulaksi muodostuu optimointialgoritmit, joiden teoreettisen ymmärryksen taso on vielä riittämättömällä tasolla optimikapasiteetin määrittelyyn. Toisin sanoen syväoppivien menetelmien kohdalla on oltava riittävästi kompleksisuutta, jotta koulutuksen aikainen testivirhe saadaan riittävän pieneksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Eräs mallin sisäisen rakenteen huomiotta jättävä keino kapasiteettiin vaikuttamiseksi on regularisoinnin (*regularizer*) käyttöönotto. Käytännössä regularisoinnilla tarkoitetaan mallin parametrien ajan mittaan tapahtuvaa heikentymistä (*decay*). Esimerkiksi edellisen esimerkin 7-asteinen malli pysyy kautta linjan samalla, mutta sen painokertoimiin vaikutetaan mahdollisesti jopa vaimentamalla suurin osa niistä jopa kokonaan regularisointikertoimella $\\lambda$. Mikäli $\\lambda$ on suuri, vain merkittävin kerroin jää vaikuttavaksi. Matala regularisointikerroin taas sallii suurempaa monimutkaisuutta. Itse malli pysyy kuitenkin koko ajan samana. Yleisemmin regularisointi määritellään kaikiksi niiksi toimiksi, joilla vaikutetaan testivirheeseen koulutusvirheen jääden koskemattomaksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.3. Hyperaparameters and Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hyperparametrit (*hyperparameters*) mainittiin jo tämän luvun alussa. Niillä tarkoitetaan mallin toimintaan vaikuttavia parametreja, joita säätämällä mallia voidaan saada paremmin sovitettua dataan. Nämä parametrit ovat niitä arvoja, joihin tukeutuen mallit oppivat. Niitä ei optimoida koulutuksen aikana mitenkään, vaan ne vaikuttavat optimointiin. Tosin, kuten aiemmassa polynomisen regression esimerkissä, näitä parametreja on mahdollista optimoida etsimällä arvot, jotka tuottavat pienimmän virheen mallin. Mikäli esimerkiksi koneoppimismalli sais itse määrittää oman kapasiteettinsa, se päätyisi aina suurimpaan mahdolliseen kapasiteettin koulutusdatan osalta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Jotta näin ei kuitenkaan pääse tapahtumaan, on data hajautettava koulutus- ja testidatan lisäksi vielä erilliseen validointisettiin. Koska koulutuksessa käytetään testisettiä testivirheen laskentaan ja täten mallin sisäisten parametrien päivitykseen, on datasetistä erotettava vielä erillinen oma osansa, jolla lopullinen yleistysvirhe (*generalization error*) mitataan. Tämä mittaus kertoo kulloinkin käytetyillä hyperparametreilla alustetun mallin suorituskyvystä. Käytännössä kyseessä on edelleen testivirhe, mutta tätä virhettä ei käytetä mallin kouluttamiseen mitenkään. Siksi on myös tärkeää, että validointisetin näytteitä ei ole käytetty mallin kouluttamisessa, ts. koulutuksen aikaisen testivirheen tuottamisessa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Käytännössä tätä varten kehitetty menetelmä tunnetaan nimellä ristiinvalidointi (*cross-validation, CV*). Ristiinvalidoinnissa datasetti $D^{m \\times n}$ jaetaan heti alussa koulutus- ja testisetteihin. Tämän jälkeen malli koulutetaan *vain* koulutusdatalla, joka ositellaan sisäisesti koulutus- ja testisetteihin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Koulutussetti $T$ ja validointisetti $V$ voidaan muodostaa esimerkiksi siten, että\n",
    "\n",
    "$$ T = 0.8n_D $$\n",
    "$$ V = 0.2n_D, $$\n",
    "\n",
    "jolloin koulutussetissä $T$ on 80% datasetin riveistä ja validointisetissä $V$ 20%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Koulutusta varten koulutussetti jaotellaan edelleen, esimerkiksi kymmeneen osaan. Tämän jälkeen koulutus suoritetaan siten, että jokainen osa toimii kerran testisettinä. Alla on sama esitetty taulukkona, jossa yksi rivi vastaa yhtä koulutuskertaa ja *t* tarkoittaa, että kyseinen koulutussetin osa toimii koulutuksen testisettinä.\n",
    "\n",
    "| $t_1$ | $t_2$ | $t_3$ | $t_4$ | $t_5$ | $t_6$ | $t_7$ | $t_8$ | $t_9$ | $t_{10}$ |\n",
    "| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | -------- |\n",
    "|   t   |       |       |       |       |       |       |       |       |      |   \n",
    "|       |   t   |       |       |       |       |       |       |       |      |    \n",
    "|       |       |   t   |       |       |       |       |       |       |      |   \n",
    "|       |       |       |   t   |       |       |       |       |       |      |   \n",
    "|       |       |       |       |   t   |       |       |       |       |      |   \n",
    "|       |       |       |       |       |   t   |       |       |       |      |   \n",
    "|       |       |       |       |       |       |   t   |       |       |      |   \n",
    "|       |       |       |       |       |       |       |   t   |       |      |   \n",
    "|       |       |       |       |       |       |       |       |   t   |      |   \n",
    "|       |       |       |       |       |       |       |       |       |   t  |\n",
    "\n",
    "Koulutuksen testivirhe lasketaan tällöin näiden koulutuskertojen keskiarvona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.4. Estimators, Bias and Variance\n",
    "\n",
    "> *Malli $\\ne$ estimaattori*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Estimointi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Estimaattorit liittyvät kiinteästi koneoppimiseen. Estimaattoreilla tarkoitetaan sellaisia funktioita, joilla pyritään löytämään parhaimmat malliin ja dataan yhdessä sopivat parametrit (esim. painot). Piste-estimaattoreilla (*point-estimator*) pyritään löytämään yksittäinen paras parametrien kokoonpano, joilla malli tuottaa kelvollisen tuloksen. Joissain tapauksissa parametrien sijasta estimoinnin kohteena voi olla kokonainen ennusteita tuottava funktio. Tällöinkin kyseessä on piste-estimoitiin palautettava ongelma, jossa piste on yksinkertaisesti yksittäinen funktio mahdollisten funktioiden joukossa tai avaruudessa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Yksinkertaistaen voitaisiin todeta, että estimaattorilla tarkoitetaan kohdefunktiota, jolla saadaan tietoa mallin suorituskyvystä. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esimerkki estimaattorista on esimerkiksi $k$-kertainen ristiinvalidointialgoritmi (*$k$-fold cross-validation*), jota voidaan käyttää koneoppimismallin testivirhettä normaalia pienemmän datasetin kanssa. Kun algoritmiin syötetään samalle datasetille koulutetut koneoppimismallit, se antaa kummallekin keskivirheen ja keskihajonnan, joidenka perusteella voidaan päätellä kahdesta mallista parempi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Vääristymä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Estimaattorin sanotaan olevan vääristynyt (*biased*), mikäli sen odotusarvo poikkeaa datasetin odotusarvosta; estimaattorin ja datasetin jakaumien ero näkyy vääristymänä (*bias*). Mikäli estimaattorin ja datasetin odotusarvot ovat samat, mallia voidaan nimittää vääristymättömäksi (*unbiased*). Vaikkakin vääristymättömät estimaattorit vaikuttavatkin lähtökohtaisesti toivotuilta, vääristyneillä estimaattoreilla on joitakin yllättäviä toivottuja ominaisuuksia, minkä vuoksi niitä käytetään useammin. Näistä lisää myöhemmin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Varianssi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Vääristymän lisäksi malleille voidaan laskea myös varianssi (*variance*). Käytännössä tämä tarkoittaa ihan samaa asiaa, kuin tilastotieteellinen varianssi, eli kuinka suuri on hajonta mallin keskiarvon ympärillä. Kuten tilastotieteessä, käytetyin hajonnan suure on keskihajonta. Datasettiä kasvattamalla on normaalisti mahdollisuus pienentää mallin varianssa *eli* lisätä sen tarkkuutta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Näitä kahta eri suunnista mallin virhettä määrittelevää suuretta, vääristymää ja varianssia, voidaan esittää tikkataulun avulla. Kun mallin vääristymä ja varianssi ovat mahdollisimman pieniä, tikat osuvat tiiviisti taulun keskialueelle. Korkean varianssin malli osuu keskimäärin keskelle, mutta tikat hajoavat laajemmalle ja pisteet jäävät näin pienemmäksi. Korkean vääristymän ja matalan varianssin malli saa tikat tiiviisti samalle alueelle, mutta tämä alue jää kauas taulun keskipisteestä. Korkean vääristymän ja varianssin malli osuu keskimäärin kunnolla ohi ja tikat menevät minne sattuu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Koneoppimismallien kanssa ollaan huomattu, että kasvattamalla mallin kapasiteettia vääristymä pienenee ja varianssi kasvaa. Tätä kutsutaan vääristymän ja varianssin vaihtokaupaksi (*bias-variance tradeoff*). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usein koneoppimisen yhteydessä käytetty estimaattori tunnetaan nimellä keskimääräinen neliövirhe (*mean squared error, MSE*). Se lasketaan keskiarvona vääristymän neliön ja varianssin summasta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.5. Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vääristymän ja varianssin tarkastelu jokaisen dataan sovitetun mallin kohdalla on verraten työlästä. Kuten ristiinvalidointiesimerkistä käy ilmi, se on tehtävä vertaillen kofiguraatioita toinen toiseensa kerta toisensa jälkeen. Suoraviivaisempaan optimaalisten parametrien selvittämiseen sopii paremmin suurimman todennäköisyyden estimointi (*maximum likelihood estimation, MLE*). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Estimaattorille syötetään datasetin lisäksi joukko keskenään vertailtavia funktioita, joista kukin on opetettu datasetille $x$ ja omaa parametrit $\\theta$. Näistä funktioista sitten valitaan paras. Parhaus määritellään sillä, kuinka samankaltainen mallin tuottama jakauma on datasetin jakaumaan nähden. Ero lasketaan hyödyntämällä aiemmin esiteltyä KL-divergenssiä, jossa vertailtavat todennäköisyysjakaumat ovat datasetin sisäinen jakauma ja mallin tuottama jakauma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Useammin on laskennallisesti järkevää kuitenkin käyttää logaritmia, jolloin liian pieniin lukuihin helposti kaatuvat kertolaskut saadaan muunnettua summauksiksi. Tästä juontaakin mm. koneoppimiskirjastoista tuttu kohdefunktion nimi *log-likelihood*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MLE on yleistetävissä ehdolliseksi lausekkeeksi, jossa etsitään suurimman ehdollisen logaritmisen todennäköisyyden (*conditional log-likelihood*) tuottavat parametrit:\n",
    "\n",
    "$$ \\theta_{ML} = \\mathop{\\arg\\max}\\limits_{\\theta} P(Y \\mid X;\\theta). $$\n",
    "\n",
    "MLE on ensisijaisesti piste-estimaattori. Merkinnällä $\\mathop{\\arg\\max}\\limits_{\\theta}$ tarkoitetaan syötettä, joka maksimoi parametrien $\\theta$ arvot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.6. Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tähän asti käsitellyt parametrien estimointimenetelmät ovat keskittyneet frekvenssisiin tilastollisiin menetelmiin (*frequentist statistics*), joissa pyritään määrittämään yksi paras parametrien arvojoukko $\\theta$. Bayesin tilastollisissa menetelmissä (*Bayesian statistics*) otetaan huomioon kaikki mahdolliset $\\theta$ parametrien joukot. Frekvenssisisssä menetelmissä lähtökohtana on, että $\\theta_{true}$ on määritelty mutta tuntematon ja estimaatti $\\hat{\\theta}$ pohjaa datasettiin ja on täten käsiteltävissä satunnaismuuttujana. Bayesin menetelmissä todennäköisyyksiä käytetään tiedon varmuuden tasojen kuvaamiseen. Datasetti havaitaan sellaisenaan eikä sitä käsitellä täten satunnaisena. Todellinen $\\theta_{true}$ käsitellään määrittelemättömänä ja esitetään satunnaismuuttujana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ennen etenemistä valitaan riittävän laveasti kattava alustava todennäköisyysjakauma (*prior probability distribution*) esimerkiksi määrittämällä arvoalueen rajat tai olettamalla arvojen olevan tasaisesti jakautuneita. Tämän jälkeen alustavaa jakaumaa testataan dataa vasten. Prosessin myötä todennäköisimmät $\\theta$:n arvot nousevat esiin muita arvoja todennäköisempinä. Menetelmä on mallinnuksen kannalta robusti, mutta laskennallisesti vaativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tämä parametrien estimointimenetelmä eroaa MLE:stä kahdella tapaa:\n",
    "\n",
    " 1. Piste-estimaation sijaan *$\\theta$ estimoidaan koko sen mahdollisen jakauman avulla*.\n",
    " 2. *Alustava todennäköisyysjakauma vaikuttaa lopullisiin parametreihin*, jolloin jakaumasta nousevat parametrien arvot ovat jonkseenkin alussa valitun alustavan jakauman tapaan tasaisesti jakautuneita.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bayesin menetelmästä on mahdollista saada ulos myös selkeämpi piste-estimaatti. Tätä menetelmää kutsutaan *maximum a posteriori (MAP)* piste-estimaatiksi. Tällöin valitaan suurimman todennäköisyyden tuottava parametrijoukko $\\theta$ ja jätetään jakauma muilta osin huomiotta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.7. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ohjatussa oppimisessa on kyse malleista, jotka oppivat kuvaamaan (*map*) syötteen $x$ ulostuloksi $\\hat{y}$ oikein arvojen $y$ avulla. Todennäköisyyksiin pohjaavassa ohjatussa oppimisessa (*probabilistic..*) tähdätään ehdollisen todennäköisyyden $p(y \\mid x)$ tuottamiseen, mikä on saavutettavissa esimerkiksi MLE:llä. Ohjatun oppimisen menetelmiä voidaan käyttää sekä regressioon että luokitteluun liittyvissä tehtävissä. Tärkeintä on, että syötedatoille löytyy lähtökohtaisesti aina ns. oikea tieto, eli joko luokka, arvo tai arvojoukko, joka kyseisellä syötteellä on havaittu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Eräs tehokas esitelty malli on tukivektorikone (*support vector machine*), joka todennäköisyyksien sijaan tuottaa binäärisiä luokittelutietoja. Luokittelu perustuu datapisteet läpäisevän suoran käyttämiseen pisteiden luokittelussa. Muita perinteisiä esiteltyjä ohjattua oppimista hyödyntäviä koneoppimismalleja ovat mm. päätöspuut (*decision trees*) ja lähimpien naapurien menetelmä (*$k$-nearest neighbours*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.8. Unuspervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vaikka tarkkaan ottaen ohjaamattoman ja ohjatun oppimisen välinen rajaviiva on häilyvä, eroavat oppimistavat toisistaan kohdetietojen osalta. Ohjaamattomassa oppimisessa syötteille ei ole oikeita vastauksia, vaan kyseistä oppimisstrategiaa hyödyntäviä menetelmiä käytetään datasta itsestään löytyvien asioiden tutkintaan. Perinteinen ohjaamattoman oppimisen ongelma sellaisen datasettia kuvaavan mallin löytäminen, joka säilyttäisi mahdollisimman paljon alkuperäisestä informaatiosta mutta olisi kuitenkin alkuperäistä datasettiä yksinkertaisempi. Yksinkertaisemmmalla tarkoitetaan joko vähempipiirteistä (*lower-dimensional*), harvaa (*sparse*) tai riippumatonta (*independent*) datasetin kuvausta mallin avulla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Aiemmin esitelty PCA-algoritmi on hyvä esimerkki piirteiden määrää karsivasta ohjaamattoman oppimisen menetelmästä. Toinen tällä alueella paljon käytetty menetelmä on *$k$-means clustering*, jossa datasetti jaetaan $k$ joukkoon eli klusteriin. Menetelmä on iteratiivinen ja se pyrkii löytämään sellaiset datan sisäiset joukot, jotka ovat stabiileja. Joukot ovat stabiileja, kun klustereiden pisteiden keskiarvot eivät muutu enää niin paljoa, että klusterien koot muuttuisivat datapisteiden suhteen. Klusteroinnissa on kuitenkin haasteena, että eri klusterointimenetelmät tai jopa -kerrat voivat klusteroida dataa eri piirteiden perusteella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.9. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Syväoppivat menetelmät ovat pääsääntöisesti kaikki koulutettavissa stokastisella eli satunnaisuuteen pohjaavalla jyrkimmän laskun menetelmällä (*stochastic gradient descent, SGD*). Se on laajennos aiemmin esitellystä *gradient descentistä*. SGD:n pohjana toimivalla perinteisellä menetelmällä laskettuna datasetin kasvaessa kasvaa myös laskennan tarve lineaarisesti, mikä muodostuu rajoittavaksi tekijäksi. SGD lähestyy tätä ongelmaa datasetistä muodostettujen pikkuerien (*minibatch*) avulla. Mallin parametreja päivitetään vain erän tultua kokonaan käsitellyksi. Kun eräkoot ovat yhdestä muutamaan sataan näytteeseen, onnistuu suurenkin datasetin sovittaminen malliin laskennallisesti kevyemmin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "SGD muodostaa eräkohtaiset gradienttien keskiarvot. Näin toimiessa ei välttämättä päästä aina edes lokaaliin minimiin, mutta kohdefunktion riittävän pieni vähentyminen onnistuu näin käyttkelpoisen lyhyessä ajassa. Siitä syystä syväoppivat menetelmät hyödyntävät tätä optimointistrategiaa. Syväoppivien mallien lisäksi muutkin mallit hyödyntävät SGD:tä, kuten suuret lineaariset mallit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.10. Perinteiset menetelmät vs. syväoppivat menetelmät"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vaikka koneoppimisalgoritmin kokoaminen on verrattain helppoa sen koostuessa itsenäisistä osista kuten datasetti, malli, optimointimenetelmä ja kohdefunktio, niin perinteisillä menetelmillä on perustavanlaatuisia ongelmia tekoälyyn liittyvien tehtävien toteuttamisessa. Näitä ovat mm. puheen tai hahmontunnistus. Näihin ongelmiin syväoppivat menetelmät ovat tarjonneet käytännössä todennettuja toimivia ja suorituskykyisiä ratkaisuja, minkä vuoksi niiden käyttöönotto on viime vuosina räjähdysmäisesti kasvanut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Eräs merkittävä koneoppimisen haaste on piirteiden kirous (*curse of dimensionality*). Kun datasetin piirreavaruus laajenee, kasvavat eri piirteiden mahdolliset konfiguraatiot eksponentiaalisesti. Matalapiirteisen datasetin kuvaaminen on vielä helppoa, kuten on yksi-, kaksi- tai kolmipiirteisen datasetin kohdalla. Kun datasetin piirremäärä kasvaa, alkaa datasetti olla piirrekohtaisesti kuitenkin sekä vaikeampaa kuvata että etenkin *harvempaa*. Tällöin datasetin piirreavaruudessa on lähtökohtaisesti enemmän aukkoja kuin dataa, jolloin dataa kuvaavan mallin kouluttaminen osoittautuu hankalaksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Jotta koneoppimismenetelmät toimisivat hyvin, niiden kohdalla on tehtävä oppimista ohjaavia ennakkopäätöksiä (\"minkälaista funktiota opetellaan?\", \"miten optimoidaan?\", jne.). Nämä päätökset määrittävät mm. sen, kuinka tasainen opittavan funktion on oltava (ks. Bayesian statistics). Näin toimittaessa tekoälyn alueella olevat ongelmat jäävät kuitenkin vaille ratkaisua. Ratkaisemattomuus ei kuitenkaan ole kiinni niinkään väärästä ennakkopäätöksestä, vaan perinteisten menetelmien kohdalla tehtävien ennakkopäätösten rajallisuudesta. Rajallisuus voidaan muotoilla kysymykseksi: Kuinka malli yleistyy löytämään kriittiset pisteet laajasta datasetistä rajallisella määrällä datapisteitä? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tähän kysymykseen syväoppivat menetelmät tarjoavat vastauksen. Nämä menetelmät oppivat datasetin tuottoprosessiin liittyviä riittävän oikeita oletuksia, jotka auttavat malleja sovittumaan tähän prosessiin rajoitetusta koulutusdatasetin koosta huolimatta. Yhdellä sanalla kysymys on datasetin rakenteesta (*structure*) ja sen oppimisesta. Perinteisten menetelmien sijaan syväoppivat menetelmät lähestyvät mallinnettavan rakenteen oppimista sillä oletuksella, että tämä rakenne muodostuu eri piirteiden yhteisvaikutuksesta (*composition of features*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Koneoppimismenetelmien taustalla vaikuttaa vahvasti ajatus merkittävien kokonaisuuksien oppimisesta (*manifold learning*). Esimerkiksi puheentunnistuksessa ei ole mitenkään mielekästä pyrkiä oppimaan koko kuultavan äänen aluetta ja johtamaan siitä erilaisten äänteiden rakenteita, vaan puheääni keskittyy normaalisti tietyille taajuusalueille. Tällöin mielekästä on pyrkiä oppimaan näiden alueiden avulla yhtenäinen kokonaisuus, johon vähemmän merkittävät alueet vaikuttavat havaitulla variaatiolla. Näin moniulotteisen tai -piirteisen datasetin opettelu pyrkii keskittymään rajatulle alueelle ja oppiminen helpottuu. Näin myös piirteiden määrää saadaan pienennettyä, jolloin datasetin rakenteen visualisointi helpottuu."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "410px",
    "width": "506px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
